{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/yassineterrab/Documents/P1/oorion/patternModel/model.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yassineterrab/Documents/P1/oorion/patternModel/model.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yassineterrab/Documents/P1/oorion/patternModel/model.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yassineterrab/Documents/P1/oorion/patternModel/model.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_categorical\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D,Dense,MaxPooling2D,Input,Flatten,Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1956 images belonging to 4 classes.\n",
      "Found 491 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1./255,rotation_range=350,shear_range=30,horizontal_flip=True,vertical_flip=True,brightness_range=(0.75,1.25),zoom_range=(0.8,1),channel_shift_range=50)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_size=1956\n",
    "val_size=491\n",
    "\n",
    "batch_size_train=8\n",
    "batch_size_val=val_size\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset_train_val/train',\n",
    "        target_size=(128,128),\n",
    "        batch_size=batch_size_train,\n",
    "        class_mode='categorical',shuffle=True)\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'dataset_train_val/val',\n",
    "        target_size=(128,128),\n",
    "        batch_size=batch_size_val,\n",
    "        class_mode='categorical',shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=(128,128,3)\n",
    "\n",
    "# Initialising the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "model.add(Conv2D(32, (3, 3), input_shape = shape, activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 4, activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=(128, 128, 3)\n",
    "\n",
    "\n",
    "model2=Sequential()\n",
    "model2.add(Input(shape=shape))\n",
    "#model2.add(Lambda(lambda x: keras.backend.mean(x, axis=3)[:, :, :, None]))\n",
    "\n",
    "model2.add(Conv2D(16, kernel_size=(3,3), activation=\"relu\"))\n",
    "model2.add(Conv2D(16, kernel_size=(3,3), activation=\"relu\"))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model2.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\"))\n",
    "model2.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\"))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model2.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\"))\n",
    "model2.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\"))\n",
    "model2.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model2.fit(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=200,  # here chose number_of_samples/batch_size\n",
    "        validation_data=validation_generator,\n",
    "        verbose=True,\n",
    "        validation_steps=1 # look at all the validation data at each epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c722a5c4612d8ea306e7964ce7d15152d9ebb0f78ff7d19afab80c6620c555e8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('test-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
